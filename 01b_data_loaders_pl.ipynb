{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09c5b0d0",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aec899fc-b62d-4933-8cc5-3cc9e5e982c3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-09T15:08:04.998180Z",
     "start_time": "2021-08-09T15:08:04.993764Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ojas/anaconda3/envs/ai/lib/python3.9/site-packages/pytorch_lightning/metrics/__init__.py:43: LightningDeprecationWarning: `pytorch_lightning.metrics.*` module has been renamed to `torchmetrics.*` and split off to its own package (https://github.com/PyTorchLightning/metrics) since v1.3 and will be removed in v1.5\n",
      "  rank_zero_deprecation(\n"
     ]
    }
   ],
   "source": [
    "#default_exp pl_dataloaders\n",
    "#export\n",
    "import warnings\n",
    "import h5py\n",
    "import os\n",
    "import io\n",
    "import numpy as np\n",
    "import json\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.transforms.functional import to_tensor\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision import transforms\n",
    "\n",
    "from torchmeta.datasets.helpers import omniglot, miniimagenet, ClassSplitter\n",
    "from torchmeta.datasets import Omniglot\n",
    "from torchmeta.utils.data import BatchMetaDataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca782e7c",
   "metadata": {},
   "source": [
    "# Custom unlabelled dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ebb3d626-82ff-4cef-9e85-b6084471e684",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-09T14:59:03.629815Z",
     "start_time": "2021-08-09T14:59:03.597451Z"
    }
   },
   "outputs": [],
   "source": [
    "#export\n",
    "class UnlabelledDataset(Dataset):\n",
    "    def __init__(self, dataset, datapath, split, transform=None,\n",
    "                 n_support=1, n_query=1, n_images=None, n_classes=None,\n",
    "                 seed=10, no_aug_support=False, no_aug_query=False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            dataset (string): Dataset name.\n",
    "            datapath (string): Directory containing the datasets.\n",
    "            split (string): The dataset split to load.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "            n_support (int): Number of support examples\n",
    "            n_query (int): Number of query examples\n",
    "            no_aug_support (bool): Wheteher to not apply any augmentations to the support\n",
    "            no_aug_query (bool): Wheteher to not apply any augmentations to the query\n",
    "            n_images (int): Limit the number of images to load.\n",
    "            n_classes (int): Limit the number of classes to load.\n",
    "            seed (int): Random seed to for selecting images to load.\n",
    "        \"\"\"\n",
    "        self.n_support = n_support\n",
    "        self.n_query = n_query\n",
    "        self.img_size = (28, 28) if dataset=='omniglot' else (84, 84)\n",
    "        self.no_aug_support = no_aug_support\n",
    "        self.no_aug_query = no_aug_query\n",
    "\n",
    "        # Get the data or paths\n",
    "        self.dataset = dataset\n",
    "        self.data = self._extract_data_from_hdf5(dataset, datapath, split, \n",
    "                                                 n_classes, seed)\n",
    "\n",
    "        # Optionally only load a subset of images\n",
    "        if n_images is not None:\n",
    "            random_idxs = np.random.RandomState(seed).permutation(len(self))[:n_images]\n",
    "            self.data = self.data[random_idxs]\n",
    "\n",
    "        # Get transform\n",
    "        if transform is not None:\n",
    "            self.transform = transform\n",
    "        else:\n",
    "            if self.dataset == 'cub':\n",
    "                self.transform = transforms.Compose([\n",
    "                    get_cub_default_transform(self.img_size),\n",
    "                    get_custom_transform(self.img_size)])\n",
    "                self.original_transform = transforms.Compose([\n",
    "                    get_cub_default_transform(self.img_size),\n",
    "                    transforms.ToTensor()])\n",
    "            elif self.dataset == 'omniglot':\n",
    "                self.transform = get_omniglot_transform((28, 28))\n",
    "                self.original_transform = identity_transform((28, 28))\n",
    "            else:\n",
    "                self.transform = get_custom_transform(self.img_size)\n",
    "                self.original_transform = identity_transform(self.img_size)\n",
    "\n",
    "    def _extract_data_from_hdf5(self, dataset, datapath, split,\n",
    "                                n_classes, seed):\n",
    "        datapath = os.path.join(datapath, dataset)\n",
    "\n",
    "        # Load omniglot\n",
    "        if dataset == 'omniglot':\n",
    "            classes = []\n",
    "            with h5py.File(os.path.join(datapath, 'data.hdf5'), 'r') as f_data:\n",
    "                with open(os.path.join(datapath,\n",
    "                          'vinyals_{}_labels.json'.format(split))) as f_labels:\n",
    "                    labels = json.load(f_labels)\n",
    "                    for label in labels:\n",
    "                        img_set, alphabet, character = label\n",
    "                        classes.append(f_data[img_set][alphabet][character][()])\n",
    "        # Load mini-imageNet\n",
    "        else:\n",
    "            with h5py.File(os.path.join(datapath, split + '_data.hdf5'), 'r') as f:\n",
    "                datasets = f['datasets']\n",
    "                classes = [datasets[k][()] for k in datasets.keys()]\n",
    "\n",
    "        # Optionally filter out some classes\n",
    "        if n_classes is not None:\n",
    "            random_idxs = np.random.RandomState(seed).permutation(len(classes))[:n_classes]\n",
    "            classes = [classes[i] for i in random_idxs]\n",
    "\n",
    "        # Collect in single array\n",
    "        data = np.concatenate(classes)\n",
    "        return data\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if self.dataset == 'cub':\n",
    "            image = Image.open(io.BytesIO(self.data[index])).convert('RGB')\n",
    "        else:\n",
    "            image = Image.fromarray(self.data[index])\n",
    "\n",
    "        view_list = []\n",
    "        \n",
    "        \n",
    "        for _ in range(self.n_support):\n",
    "            if not self.no_aug_support:\n",
    "                view_list.append(self.transform(image).unsqueeze(0))\n",
    "            else:\n",
    "                assert self.n_support == 1\n",
    "                view_list.append(self.original_transform(image).unsqueeze(0))\n",
    "        \n",
    "        for _ in range(self.n_query):\n",
    "            if not self.no_aug_query:\n",
    "                view_list.append(self.transform(image).unsqueeze(0))\n",
    "            else:\n",
    "                assert self.n_query == 1\n",
    "                view_list.append(self.original_transform(image).unsqueeze(0))\n",
    "        \n",
    "        return dict(data=torch.cat(view_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8dcaea3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-09T15:00:30.698362Z",
     "start_time": "2021-08-09T15:00:30.686124Z"
    }
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def get_cub_default_transform(size):\n",
    "    return transforms.Compose([\n",
    "        transforms.Resize([int(size[0] * 1.5), int(size[1] * 1.5)]),\n",
    "        transforms.CenterCrop(size)])\n",
    "\n",
    "def get_simCLR_transform(img_shape):\n",
    "    \"\"\"Adapted from https://github.com/sthalles/SimCLR/blob/master/data_aug/dataset_wrapper.py\"\"\"\n",
    "    color_jitter = transforms.ColorJitter(brightness=0.8, contrast=0.8,\n",
    "                                          saturation=0.8, hue=0.2)\n",
    "    data_transforms = transforms.Compose([transforms.RandomResizedCrop(size=img_shape[-2:]),\n",
    "                                          transforms.RandomHorizontalFlip(),\n",
    "                                          transforms.RandomApply([color_jitter], p=0.8),\n",
    "                                          transforms.RandomGrayscale(p=0.2),\n",
    "                                         # GaussianBlur(kernel_size=int(0.1 * self.input_shape[0])),\n",
    "                                          transforms.ToTensor()])\n",
    "    return data_transforms\n",
    "\n",
    "def get_omniglot_transform(img_shape):\n",
    "    data_transforms = transforms.Compose([\n",
    "                                          transforms.Resize(img_shape[-2:]),\n",
    "                                          transforms.RandomResizedCrop(size=img_shape[-2:],\n",
    "                                                                       scale=(0.6, 1.4)),\n",
    "                                          transforms.RandomHorizontalFlip(p=0.5),\n",
    "                                          transforms.RandomVerticalFlip(p=0.5),\n",
    "                                          transforms.ToTensor(),\n",
    "                                          transforms.Lambda(lambda t: F.dropout(t, p=0.3)),\n",
    "                                          transforms.RandomErasing()\n",
    "                                          ])\n",
    "    return data_transforms\n",
    "\n",
    "def get_custom_transform(img_shape):\n",
    "    color_jitter = transforms.ColorJitter(brightness=0.4, contrast=0.4,\n",
    "                                          saturation=0.4, hue=0.1)\n",
    "    data_transforms = transforms.Compose([transforms.RandomResizedCrop(size=img_shape[-2:],\n",
    "                                                                       scale=(0.5, 1.0)),\n",
    "                                          transforms.RandomHorizontalFlip(p=0.5),\n",
    "                                          transforms.RandomVerticalFlip(p=0.5),\n",
    "                                          transforms.RandomApply([color_jitter], p=0.8),\n",
    "                                          transforms.RandomGrayscale(p=0.2),\n",
    "                                          transforms.ToTensor()])\n",
    "    return data_transforms\n",
    "\n",
    "def identity_transform(img_shape):\n",
    "    return transforms.Compose([transforms.Resize(img_shape),\n",
    "                               transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b286dc91-b293-43dd-96f8-ba87ed5d3e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "class UnlabelledDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, dataset, datapath, split, transform=None,\n",
    "                 n_support=1, n_query=1, n_images=None, n_classes=None,\n",
    "                 seed=10, no_aug_support=False, no_aug_query=False, merge_train_val=False):\n",
    "        self.n_images = n_images\n",
    "        self.n_support = n_support\n",
    "        self.n_query = n_query\n",
    "        self.img_size = (28, 28) if dataset=='omniglot' else (84, 84)\n",
    "        self.no_aug_support = no_aug_support\n",
    "        self.no_aug_query = no_aug_query\n",
    "\n",
    "        # Get the data or paths\n",
    "        self.dataset = dataset\n",
    "        self.datapath = datapath\n",
    "        \n",
    "        self.merge_train_val = merge_train_val\n",
    "        \n",
    "    def setup(self, stage=None):\n",
    "        self.dataset_train = UnlabelledDataset(self.dataset,\n",
    "                                          self.datapath, split='train',\n",
    "                                          transform=None,\n",
    "                                          n_images=self.n_images,\n",
    "                                          n_classes=self.n_classes,\n",
    "                                          n_support=self.n_support,\n",
    "                                          n_query=self.n_query,\n",
    "                                          no_aug_support=self.no_aug_support,\n",
    "                                          no_aug_query=self.no_aug_query)\n",
    "        if self.merge_train_val:\n",
    "            dataset_val = UnlabelledDataset(args.dataset, args.datapath, 'val',\n",
    "                                            transform=None,\n",
    "                                            n_support=self.n_support,\n",
    "                                            n_query=self.n_query,\n",
    "                                            no_aug_support=self.no_aug_support,\n",
    "                                            no_aug_query=self.no_aug_query)\n",
    "\n",
    "            self.dataset_train = ConcatDataset([dataset_train, dataset_val])\n",
    "            \n",
    "    def train_dataloader(self):\n",
    "        dataloader_train = DataLoader(self.dataset_train,\n",
    "                                      batch_size=args.batch_size,\n",
    "                                      shuffle=True,\n",
    "                                      num_workers=num_workers,\n",
    "                                      pin_memory=torch.cuda.is_available())\n",
    "        return dataloader_train\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        dataset_val = UnlabelledDataset(args.dataset, args.datapath, 'val',\n",
    "                                            transform=None,\n",
    "                                            n_support=self.n_support,\n",
    "                                            n_query=self.n_query,\n",
    "                                            no_aug_support=self.no_aug_support,\n",
    "                                            no_aug_query=self.no_aug_query)\n",
    "        dataloader_val = DataLoader(dataset_val,\n",
    "                                      batch_size=args.batch_size,\n",
    "                                      shuffle=True,\n",
    "                                      num_workers=num_workers,\n",
    "                                      pin_memory=torch.cuda.is_available())\n",
    "        \n",
    "        return dataloader_val\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2150b382-d13f-4df1-b25a-81dd23d28dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class OmniglotDataModule(pl.LightningDataModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        data_dir: str,\n",
    "        shots: int,\n",
    "        ways: int,\n",
    "        shuffle_ds: bool,\n",
    "        test_shots: int,\n",
    "        meta_train: bool,\n",
    "        download: bool,\n",
    "        batch_size: str,\n",
    "        shuffle: bool,\n",
    "        num_workers: int):\n",
    "        super().__init__()\n",
    "        self.data_dir = data_dir\n",
    "        self.shots = shots\n",
    "        self.ways = ways\n",
    "        self.shuffle_ds = shuffle_ds\n",
    "        self.test_shots = test_shots\n",
    "        self.meta_train = meta_train\n",
    "        self.download = download\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.num_workers = num_workers\n",
    "    \n",
    "    def setup(self, stage=None):\n",
    "        self.task_dataset = omniglot(\n",
    "            self.data_dir,\n",
    "            shots=self.shots,\n",
    "            ways=self.ways,\n",
    "            shuffle=self.shuffle_ds,\n",
    "            test_shots=self.test_shots,\n",
    "            meta_train=self.meta_train,\n",
    "            download=self.download\n",
    "        )\n",
    "    def train_dataloader(self):\n",
    "        return BatchMetaDataLoader(\n",
    "            self.task_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=self.shuffle,\n",
    "            num_workers=self.num_workers\n",
    "        )\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        self.val_tasks = omniglot(\n",
    "            self.data_dir,\n",
    "            shots=self.shots,\n",
    "            ways=self.ways,\n",
    "            shuffle=self.shuffle_ds,\n",
    "            test_shots=self.test_shots,\n",
    "            meta_val=True,\n",
    "            download=self.download\n",
    "        )\n",
    "        return BatchMetaDataLoader(\n",
    "            self.val_tasks,\n",
    "            batch_size=self.batch_size,\n",
    "            num_workers=self.num_workers\n",
    "        )\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        self.test_tasks = omniglot(\n",
    "            self.data_dir,\n",
    "            shots=self.shots,\n",
    "            ways=self.ways,\n",
    "            shuffle=self.shuffle_ds,\n",
    "            test_shots=self.test_shots,\n",
    "            meta_test=True,\n",
    "            download=self.download\n",
    "        )\n",
    "        return BatchMetaDataLoader(\n",
    "            self.test_tasks,\n",
    "            batch_size=self.batch_size,\n",
    "            num_workers=self.num_workers\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8f0ac6-2bce-4e91-b2f2-f0a3bc6a81d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = omniglot(\n",
    "            'data/',\n",
    "            shots=1,\n",
    "            ways=5,\n",
    "            shuffle=True,\n",
    "            test_shots=15,\n",
    "            meta_train=True,\n",
    "            download=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7183c7dd-65e1-45dd-bcbd-51fee227857e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = BatchMetaDataLoader(\n",
    "            ds,\n",
    "            batch_size=16,\n",
    "            num_workers=4\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a943ce4-72e2-4a8f-881f-46fb22a101a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ojass/anaconda3/envs/jax/lib/python3.9/site-packages/torchvision/transforms/functional.py:942: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "/home/ojass/anaconda3/envs/jax/lib/python3.9/site-packages/torchvision/transforms/functional.py:942: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "/home/ojass/anaconda3/envs/jax/lib/python3.9/site-packages/torchvision/transforms/functional.py:942: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "/home/ojass/anaconda3/envs/jax/lib/python3.9/site-packages/torchvision/transforms/functional.py:942: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 75, 1, 28, 28])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(dl))['test'][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64d4ec5-57cb-4cc4-b753-1c6399213c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class MiniImagenetDataModule(pl.LightningDataModule):\n",
    "    def __init__(self,\n",
    "                 data_dir: str,\n",
    "                 shots: int,\n",
    "                 ways: int,\n",
    "                 shuffle_ds: bool,\n",
    "                 test_shots: int,\n",
    "                 meta_train: bool,\n",
    "                 download: bool,\n",
    "                 batch_size: str,\n",
    "                 shuffle: bool,\n",
    "                 num_workers: int):\n",
    "        self.data_dir = data_dir\n",
    "        self.shots = shots\n",
    "        self.ways = ways\n",
    "        self.shuffle_ds = shuffle_ds\n",
    "        self.test_shots = test_shots\n",
    "        self.meta_train = meta_train\n",
    "        self.download = download\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.num_workers = num_workers\n",
    "    \n",
    "    def setup(self):\n",
    "        self.train_taskset = miniimagenet(\n",
    "            self.data_dir,\n",
    "            shots=self.shots,\n",
    "            ways=self.ways,\n",
    "            shuffle=self.shuffle_ds,\n",
    "            test_shots=self.test_shots,\n",
    "            meta_train=True,\n",
    "            download=self.download\n",
    "        )\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        return BatchMetaDataLoader(\n",
    "            self.train_taskset,\n",
    "            shuffle=self.shuffle,\n",
    "            batch_size=self.batch_size,\n",
    "            num_workers=self.num_workers\n",
    "        )\n",
    "    def val_dataloader(self):\n",
    "        self.val_taskset = miniimagenet(\n",
    "            self.data_dir,\n",
    "            shots=self.shots,\n",
    "            ways=self.ways,\n",
    "            shuffle=self.shuffle_ds,\n",
    "            test_shots=self.test_shots,\n",
    "            meta_val=True,\n",
    "            download=self.download\n",
    "        )\n",
    "        return BatchMetaDataLoader(\n",
    "            self.val_taskset,\n",
    "            shuffle=self.shuffle,\n",
    "            batch_size=self.batch_size,\n",
    "            num_workers=self.num_workers\n",
    "        )\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        self.test_taskset = miniimagenet(\n",
    "            self.data_dir,\n",
    "            shots=self.shots,\n",
    "            ways=self.ways,\n",
    "            shuffle=False,\n",
    "            test_shots=self.test_shots,\n",
    "            meta_test=True,\n",
    "            download=self.download\n",
    "        )\n",
    "        return BatchMetaDataLoader(\n",
    "            self.test_taskset,\n",
    "            shuffle=False,\n",
    "            batch_size=self.batch_size,\n",
    "            num_workers=self.num_workers\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9875c16c-dbf5-4756-afaa-b17c8833acc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = omniglot(\n",
    "            'data/',\n",
    "            shots=1,\n",
    "            ways=5,\n",
    "            shuffle=False,\n",
    "            test_shots=15,\n",
    "            meta_train=True,\n",
    "            download=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94aaea8c-769f-4d57-9929-aafbf408bf58",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = BatchMetaDataLoader(ds, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0beccfe-115c-41bd-a14b-2881a4a624f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ojass/anaconda3/envs/jax/lib/python3.9/site-packages/torchvision/transforms/functional.py:942: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0, 3, 1, 4, 2],\n",
       "        [4, 2, 0, 1, 3],\n",
       "        [4, 0, 3, 2, 1],\n",
       "        [1, 4, 3, 2, 0],\n",
       "        [4, 0, 2, 3, 1],\n",
       "        [0, 2, 1, 3, 4],\n",
       "        [2, 1, 0, 4, 3],\n",
       "        [4, 2, 1, 3, 0],\n",
       "        [0, 3, 2, 1, 4],\n",
       "        [0, 1, 4, 3, 2],\n",
       "        [0, 1, 2, 3, 4],\n",
       "        [2, 4, 1, 0, 3],\n",
       "        [4, 0, 3, 1, 2],\n",
       "        [2, 4, 0, 3, 1],\n",
       "        [0, 3, 1, 4, 2],\n",
       "        [3, 1, 2, 0, 4]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(dl))['train'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9c3c58-6b15-403d-8f40-36b9c396c696",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_cub_default_transform(size):\n",
    "    return transforms.Compose([\n",
    "        transforms.Resize([int(size[0] * 1.5), int(size[1] * 1.5)]),\n",
    "        transforms.CenterCrop(size)])\n",
    "\n",
    "def get_simCLR_transform(img_shape):\n",
    "    \"\"\"Adapted from https://github.com/sthalles/SimCLR/blob/master/data_aug/dataset_wrapper.py\"\"\"\n",
    "    color_jitter = transforms.ColorJitter(brightness=0.8, contrast=0.8,\n",
    "                                          saturation=0.8, hue=0.2)\n",
    "    data_transforms = transforms.Compose([transforms.RandomResizedCrop(size=img_shape[-2:]),\n",
    "                                          transforms.RandomHorizontalFlip(),\n",
    "                                          transforms.RandomApply([color_jitter], p=0.8),\n",
    "                                          transforms.RandomGrayscale(p=0.2),\n",
    "                                         # GaussianBlur(kernel_size=int(0.1 * self.input_shape[0])),\n",
    "                                          transforms.ToTensor()])\n",
    "    return data_transforms\n",
    "\n",
    "def get_omniglot_transform(img_shape):\n",
    "    data_transforms = transforms.Compose([\n",
    "                                          transforms.Resize(img_shape[-2:]),\n",
    "                                          transforms.RandomResizedCrop(size=img_shape[-2:],\n",
    "                                                                       scale=(0.6, 1.4)),\n",
    "                                          transforms.RandomHorizontalFlip(p=0.5),\n",
    "                                          transforms.RandomVerticalFlip(p=0.5),\n",
    "                                          transforms.ToTensor(),\n",
    "                                          transforms.Lambda(lambda t: F.dropout(t, p=0.3)),\n",
    "                                          transforms.RandomErasing()\n",
    "                                          ])\n",
    "    return data_transforms\n",
    "\n",
    "def get_custom_transform(img_shape):\n",
    "    color_jitter = transforms.ColorJitter(brightness=0.4, contrast=0.4,\n",
    "                                          saturation=0.4, hue=0.1)\n",
    "    data_transforms = transforms.Compose([transforms.RandomResizedCrop(size=img_shape[-2:],\n",
    "                                                                       scale=(0.5, 1.0)),\n",
    "                                          transforms.RandomHorizontalFlip(p=0.5),\n",
    "                                          transforms.RandomVerticalFlip(p=0.5),\n",
    "                                          transforms.RandomApply([color_jitter], p=0.8),\n",
    "                                          transforms.RandomGrayscale(p=0.2),\n",
    "                                          transforms.ToTensor()])\n",
    "    return data_transforms\n",
    "\n",
    "def identity_transform(img_shape):\n",
    "    return transforms.Compose([transforms.Resize(img_shape),\n",
    "                               transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0fb0c0-7155-4888-b5a9-3d067bc6f6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class UnlabelledDataset(Dataset):\n",
    "    def __init__(self, dataset, datapath, split, transform=None,\n",
    "                 n_support=1, n_query=1, n_images=None, n_classes=None,\n",
    "                 seed=10, no_aug_support=False, no_aug_query=False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            dataset (string): Dataset name.\n",
    "            datapath (string): Directory containing the datasets.\n",
    "            split (string): The dataset split to load.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "            n_support (int): Number of support examples\n",
    "            n_query (int): Number of query examples\n",
    "            no_aug_support (bool): Wheteher to not apply any augmentations to the support\n",
    "            no_aug_query (bool): Wheteher to not apply any augmentations to the query\n",
    "            n_images (int): Limit the number of images to load.\n",
    "            n_classes (int): Limit the number of classes to load.\n",
    "            seed (int): Random seed to for selecting images to load.\n",
    "        \"\"\"\n",
    "        self.n_support = n_support\n",
    "        self.n_query = n_query\n",
    "        self.img_size = (28, 28) if dataset=='omniglot' else (84, 84)\n",
    "        self.no_aug_support = no_aug_support\n",
    "        self.no_aug_query = no_aug_query\n",
    "\n",
    "        # Get the data or paths\n",
    "        self.dataset = dataset\n",
    "        self.data = self._extract_data_from_hdf5(dataset, datapath, split, \n",
    "                                                 n_classes, seed)\n",
    "\n",
    "        # Optionally only load a subset of images\n",
    "        if n_images is not None:\n",
    "            random_idxs = np.random.RandomState(seed).permutation(len(self))[:n_images]\n",
    "            self.data = self.data[random_idxs]\n",
    "\n",
    "        # Get transform\n",
    "        if transform is not None:\n",
    "            self.transform = transform\n",
    "        else:\n",
    "            if self.dataset == 'cub':\n",
    "                self.transform = transforms.Compose([\n",
    "                    get_cub_default_transform(self.img_size),\n",
    "                    get_custom_transform(self.img_size)])\n",
    "                self.original_transform = transforms.Compose([\n",
    "                    get_cub_default_transform(self.img_size),\n",
    "                    transforms.ToTensor()])\n",
    "            elif self.dataset == 'omniglot':\n",
    "                self.transform = get_omniglot_transform((28, 28))\n",
    "                self.original_transform = identity_transform((28, 28))\n",
    "            else:\n",
    "                self.transform = get_custom_transform(self.img_size)\n",
    "                self.original_transform = identity_transform(self.img_size)\n",
    "\n",
    "    def _extract_data_from_hdf5(self, dataset, datapath, split,\n",
    "                                n_classes, seed):\n",
    "        datapath = os.path.join(datapath, dataset)\n",
    "\n",
    "        # Load omniglot\n",
    "        if dataset == 'omniglot':\n",
    "            classes = []\n",
    "            with h5py.File(os.path.join(datapath, 'data.hdf5'), 'r') as f_data:\n",
    "                with open(os.path.join(datapath,\n",
    "                          'vinyals_{}_labels.json'.format(split))) as f_labels:\n",
    "                    labels = json.load(f_labels)\n",
    "                    for label in labels:\n",
    "                        img_set, alphabet, character = label\n",
    "                        classes.append(f_data[img_set][alphabet][character][()])\n",
    "        # Load mini-imageNet\n",
    "        else:\n",
    "            with h5py.File(os.path.join(datapath, split + '_data.hdf5'), 'r') as f:\n",
    "                datasets = f['datasets']\n",
    "                classes = [datasets[k][()] for k in datasets.keys()]\n",
    "\n",
    "        # Optionally filter out some classes\n",
    "        if n_classes is not None:\n",
    "            random_idxs = np.random.RandomState(seed).permutation(len(classes))[:n_classes]\n",
    "            classes = [classes[i] for i in random_idxs]\n",
    "\n",
    "        # Collect in single array\n",
    "        data = np.concatenate(classes)\n",
    "        return data\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if self.dataset == 'cub':\n",
    "            image = Image.open(io.BytesIO(self.data[index])).convert('RGB')\n",
    "        else:\n",
    "            image = Image.fromarray(self.data[index])\n",
    "\n",
    "        view_list = []\n",
    "        \n",
    "        \n",
    "        for _ in range(self.n_support):\n",
    "            if not self.no_aug_support:\n",
    "                view_list.append(self.transform(image).unsqueeze(0))\n",
    "            else:\n",
    "                assert self.n_support == 1\n",
    "                view_list.append(self.original_transform(image).unsqueeze(0))\n",
    "        \n",
    "        for _ in range(self.n_query):\n",
    "            if not self.no_aug_query:\n",
    "                view_list.append(self.transform(image).unsqueeze(0))\n",
    "            else:\n",
    "                assert self.n_query == 1\n",
    "                view_list.append(self.original_transform(image).unsqueeze(0))\n",
    "        \n",
    "        return dict(data=torch.cat(view_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f200a773-2d12-42df-a3b8-afb86cb8c7e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 01_nn_utils.ipynb.\n",
      "Converted 01b_data_loaders_pl.ipynb.\n",
      "Converted 01c_grad_utils.ipynb.\n",
      "Converted 01d_proto_utils.ipynb.\n",
      "Converted 02_maml_pl.ipynb.\n",
      "Converted 02b_iMAML.ipynb.\n",
      "Converted 03_protonet_pl.ipynb.\n",
      "Converted 03b_ProtoCLR.ipynb.\n",
      "Converted 04_cactus.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "from nbdev.export import notebook2script; notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ddee860-4987-4032-bfc7-a52f4fae77c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "280px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
