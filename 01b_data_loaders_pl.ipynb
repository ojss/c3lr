{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp pl_dataloaders\n",
    "# export\n",
    "\n",
    "import io\n",
    "import json\n",
    "import os\n",
    "from collections import OrderedDict\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "from PIL import Image\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import ConcatDataset, DataLoader, Dataset\n",
    "from torch.utils.data.dataloader import default_collate\n",
    "from torchmeta.datasets.helpers import (cifar_fs, cub, doublemnist,\n",
    "                                        miniimagenet, omniglot, tieredimagenet,\n",
    "                                        triplemnist)\n",
    "from torchmeta.utils.data import BatchMetaDataLoader, MetaDataLoader\n",
    "from torchvision import transforms\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helpers to create normal tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def collate_task(task):\n",
    "    if isinstance(task, Dataset):\n",
    "        return default_collate([task[idx] for idx in range(len(task))])\n",
    "    elif isinstance(task, OrderedDict):\n",
    "        return OrderedDict([(key, collate_task(subtask))\n",
    "            for (key, subtask) in task.items()])\n",
    "    else:\n",
    "        raise NotImplementedError()\n",
    "\n",
    "def collate_task_batch(batch):\n",
    "    return default_collate([collate_task(task) for task in batch])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_episode_loader(dataset, datapath, ways, shots, test_shots, batch_size,\n",
    "                       split, download=True, shuffle=True, num_workers=0):\n",
    "    \"\"\"Create an episode data loader for a torchmeta dataset. Can also\n",
    "    include unlabelled data for semi-supervised learning.\n",
    "\n",
    "    dataset: String. Name of the dataset to use.\n",
    "    datapath: String. Path, where dataset are stored.\n",
    "    ways: Integer. Number of ways N.\n",
    "    shots: Integer. Number of shots K for support set.\n",
    "    test_shots: Integer. Number of images in query set.\n",
    "    batch_size: Integer. Number of tasks per iteration.\n",
    "    split: String. One of ['train', 'val', 'test']\n",
    "    download: Boolean. Whether to download the data.\n",
    "    shuffle: Boolean. Whether to shuffle episodes.\n",
    "    \"\"\"\n",
    "    # Select dataset\n",
    "    if dataset == 'omniglot':\n",
    "        dataset_func = omniglot\n",
    "    elif dataset == 'miniimagenet':\n",
    "        dataset_func = miniimagenet\n",
    "    elif dataset == 'tieredimagenet':\n",
    "        dataset_func = tieredimagenet\n",
    "    elif dataset == 'cub':\n",
    "        dataset_func = cub\n",
    "    elif dataset == 'cifar_fs':\n",
    "        dataset_func = cifar_fs\n",
    "    elif dataset == 'doublemnist':\n",
    "        dataset_func = doublemnist\n",
    "    elif dataset == 'triplemnist':\n",
    "        dataset_func = triplemnist\n",
    "    else:\n",
    "        raise ValueError(\"No such dataset available. Please choose from\\\n",
    "                         ['omniglot', 'miniimagenet', 'tieredimagenet',\\\n",
    "                          'cub, cifar_fs, doublemnist, triplemnist']\")\n",
    "\n",
    "    # Collect arguments that are the same for all possible sub-datasets\n",
    "    kwargs = {'download': download,\n",
    "              'meta_train': split=='train',\n",
    "              'meta_val': split=='val',\n",
    "              'meta_test': split=='test',\n",
    "              'shuffle': shuffle}\n",
    "\n",
    "    # Create dataset for labelled images\n",
    "    dataset_name = dataset\n",
    "    dataset = dataset_func(datapath,\n",
    "                           ways=ways,\n",
    "                           shots=shots,\n",
    "                           test_shots=test_shots,\n",
    "                           **kwargs)\n",
    "\n",
    "    print('Supervised data loader for {}:{}.'.format(dataset_name, split))\n",
    "    # Standard supervised meta-learning dataloader\n",
    "    collate_fn = collate_task_batch if batch_size else collate_task\n",
    "    return MetaDataLoader(dataset, batch_size=batch_size,\n",
    "                          collate_fn=collate_fn,\n",
    "                          num_workers=num_workers,\n",
    "                          pin_memory=torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom unlabelled dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class UnlabelledDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dataset,\n",
    "        datapath,\n",
    "        split,\n",
    "        transform=None,\n",
    "        n_support=1,\n",
    "        n_query=1,\n",
    "        n_images=None,\n",
    "        n_classes=None,\n",
    "        seed=10,\n",
    "        no_aug_support=False,\n",
    "        no_aug_query=False,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            dataset (string): Dataset name.\n",
    "            datapath (string): Directory containing the datasets.\n",
    "            split (string): The dataset split to load.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "            n_support (int): Number of support examples\n",
    "            n_query (int): Number of query examples\n",
    "            no_aug_support (bool): Wheteher to not apply any augmentations to the support\n",
    "            no_aug_query (bool): Wheteher to not apply any augmentations to the query\n",
    "            n_images (int): Limit the number of images to load.\n",
    "            n_classes (int): Limit the number of classes to load.\n",
    "            seed (int): Random seed to for selecting images to load.\n",
    "        \"\"\"\n",
    "        self.n_support = n_support\n",
    "        self.n_query = n_query\n",
    "        self.img_size = (28, 28) if dataset == \"omniglot\" else (84, 84)\n",
    "        self.no_aug_support = no_aug_support\n",
    "        self.no_aug_query = no_aug_query\n",
    "\n",
    "        # Get the data or paths\n",
    "        self.dataset = dataset\n",
    "        self.data, self.targets = self._extract_data_from_hdf5(\n",
    "            dataset, datapath, split, n_classes, seed\n",
    "        )\n",
    "\n",
    "        # Optionally only load a subset of images\n",
    "        if n_images is not None:\n",
    "            random_idxs = np.random.RandomState(seed).permutation(len(self))[:n_images]\n",
    "            self.data = self.data[random_idxs]\n",
    "\n",
    "        # Get transform\n",
    "        if transform is not None:\n",
    "            self.transform = transform\n",
    "        else:\n",
    "            if self.dataset == \"cub\":\n",
    "                self.transform = transforms.Compose(\n",
    "                    [\n",
    "                        get_cub_default_transform(self.img_size),\n",
    "                        get_custom_transform(self.img_size),\n",
    "                    ]\n",
    "                )\n",
    "                self.original_transform = transforms.Compose(\n",
    "                    [get_cub_default_transform(self.img_size), transforms.ToTensor()]\n",
    "                )\n",
    "            elif self.dataset == \"omniglot\":\n",
    "                self.transform = get_omniglot_transform((28, 28))\n",
    "                self.original_transform = identity_transform((28, 28))\n",
    "            else:\n",
    "                self.transform = get_custom_transform(self.img_size)\n",
    "                self.original_transform = identity_transform(self.img_size)\n",
    "\n",
    "    def _extract_data_from_hdf5(self, dataset, datapath, split, n_classes, seed):\n",
    "        datapath = os.path.join(datapath, dataset)\n",
    "        targets = []\n",
    "        # Load omniglot\n",
    "        if dataset == \"omniglot\":\n",
    "            classes = []\n",
    "            with h5py.File(os.path.join(datapath, \"data.hdf5\"), \"r\") as f_data:\n",
    "                with open(\n",
    "                    os.path.join(datapath, \"vinyals_{}_labels.json\".format(split))\n",
    "                ) as f_labels:\n",
    "                    labels = json.load(f_labels)\n",
    "                    for label in labels:\n",
    "                        img_set, alphabet, character = label\n",
    "                        classes.append(\n",
    "                            (f_data[img_set][alphabet][character][()], \"/\".join(label))\n",
    "                        )\n",
    "        # Load mini-imageNet\n",
    "        else:\n",
    "            with h5py.File(os.path.join(datapath, split + \"_data.hdf5\"), \"r\") as f:\n",
    "                datasets = f[\"datasets\"]\n",
    "                classes = [datasets[k][()] for k in datasets.keys()]\n",
    "\n",
    "        # Optionally filter out some classes)\n",
    "        if n_classes is not None:\n",
    "            random_idxs = np.random.RandomState(seed).permutation(len(classes))[\n",
    "                :n_classes\n",
    "            ]\n",
    "            classes = [classes[i] for i in random_idxs]\n",
    "\n",
    "        # Collect in single array\n",
    "        targets = targets = np.array(\n",
    "            LabelEncoder().fit_transform([x[1] for x in classes])\n",
    "        ).repeat(20)\n",
    "        classes = [x[0] for x in classes]\n",
    "        data = np.concatenate(classes)\n",
    "        return data, targets\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if self.dataset == \"cub\":\n",
    "            target = self.data[index]\n",
    "            image = Image.open(io.BytesIO(self.data[index])).convert(\"RGB\")\n",
    "        else:\n",
    "            target = self.data[index]\n",
    "            image = Image.fromarray(self.data[index])\n",
    "\n",
    "        view_list = []\n",
    "        targets = []\n",
    "\n",
    "        for _ in range(self.n_support):\n",
    "            if not self.no_aug_support:\n",
    "                view_list.append(self.transform(image).unsqueeze(0))\n",
    "                targets.append(target)\n",
    "            else:\n",
    "                assert self.n_support == 1\n",
    "                view_list.append(self.original_transform(image).unsqueeze(0))\n",
    "                targets.append(target)\n",
    "\n",
    "        for _ in range(self.n_query):\n",
    "            if not self.no_aug_query:\n",
    "                view_list.append(self.transform(image).unsqueeze(0))\n",
    "                targets.append(target)\n",
    "            else:\n",
    "                assert self.n_query == 1\n",
    "                view_list.append(self.original_transform(image).unsqueeze(0))\n",
    "                targets.append(target)\n",
    "\n",
    "        return dict(data=torch.cat(view_list), labels=targets)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def get_cub_default_transform(size):\n",
    "    return transforms.Compose(\n",
    "        [\n",
    "            transforms.Resize([int(size[0] * 1.5), int(size[1] * 1.5)]),\n",
    "            transforms.CenterCrop(size),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "def get_simCLR_transform(img_shape):\n",
    "    \"\"\"Adapted from https://github.com/sthalles/SimCLR/blob/master/data_aug/dataset_wrapper.py\"\"\"\n",
    "    color_jitter = transforms.ColorJitter(\n",
    "        brightness=0.8, contrast=0.8, saturation=0.8, hue=0.2\n",
    "    )\n",
    "    data_transforms = transforms.Compose(\n",
    "        [\n",
    "            transforms.RandomResizedCrop(size=img_shape[-2:]),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomApply([color_jitter], p=0.8),\n",
    "            transforms.RandomGrayscale(p=0.2),\n",
    "            # GaussianBlur(kernel_size=int(0.1 * self.input_shape[0])),\n",
    "            transforms.ToTensor(),\n",
    "        ]\n",
    "    )\n",
    "    return data_transforms\n",
    "\n",
    "\n",
    "def get_omniglot_transform(img_shape):\n",
    "    data_transforms = transforms.Compose(\n",
    "        [\n",
    "            transforms.Resize(img_shape[-2:]),\n",
    "            transforms.RandomResizedCrop(size=img_shape[-2:], scale=(0.6, 1.4)),\n",
    "            transforms.RandomHorizontalFlip(p=0.5),\n",
    "            transforms.RandomVerticalFlip(p=0.5),\n",
    "            transforms.ToTensor(),\n",
    "            #   transforms.Lambda(lambda t: F.dropout(t, p=0.3)),\n",
    "            transforms.RandomErasing(),\n",
    "        ]\n",
    "    )\n",
    "    return data_transforms\n",
    "\n",
    "\n",
    "def get_custom_transform(img_shape):\n",
    "    color_jitter = transforms.ColorJitter(\n",
    "        brightness=0.4, contrast=0.4, saturation=0.4, hue=0.1\n",
    "    )\n",
    "    data_transforms = transforms.Compose(\n",
    "        [\n",
    "            transforms.RandomResizedCrop(size=img_shape[-2:], scale=(0.5, 1.0)),\n",
    "            transforms.RandomHorizontalFlip(p=0.5),\n",
    "            transforms.RandomVerticalFlip(p=0.5),\n",
    "            transforms.RandomApply([color_jitter], p=0.8),\n",
    "            transforms.RandomGrayscale(p=0.2),\n",
    "            transforms.ToTensor(),\n",
    "        ]\n",
    "    )\n",
    "    return data_transforms\n",
    "\n",
    "\n",
    "def identity_transform(img_shape):\n",
    "    return transforms.Compose([transforms.Resize(img_shape), transforms.ToTensor()])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unlabelled Data Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "class UnlabelledDataModule(pl.LightningDataModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dataset,\n",
    "        datapath,\n",
    "        split,\n",
    "        transform=None,\n",
    "        n_support=1,\n",
    "        n_query=1,\n",
    "        n_images=None,\n",
    "        n_classes=None,\n",
    "        batch_size=50,\n",
    "        num_workers=8,\n",
    "        seed=10,\n",
    "        no_aug_support=False,\n",
    "        no_aug_query=False,\n",
    "        merge_train_val=True,\n",
    "        mode=\"val\",\n",
    "        eval_ways=5,\n",
    "        eval_support_shots=5,\n",
    "        eval_query_shots=15,\n",
    "        train_oracle_mode=False,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.n_images = n_images\n",
    "        self.n_support = n_support\n",
    "        self.n_query = n_query\n",
    "        self.n_classes = n_classes\n",
    "        self.img_size = (28, 28) if dataset == \"omniglot\" else (84, 84)\n",
    "        self.no_aug_support = no_aug_support\n",
    "        self.no_aug_query = no_aug_query\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "\n",
    "        # Get the data or paths\n",
    "        self.dataset = dataset\n",
    "        self.datapath = datapath\n",
    "\n",
    "        self.mode = mode\n",
    "\n",
    "        self.eval_ways = eval_ways\n",
    "        self.eval_support_shots = eval_support_shots\n",
    "        self.eval_query_shots = eval_query_shots\n",
    "\n",
    "        self.merge_train_val = merge_train_val\n",
    "\n",
    "        self.train_oracle_mode = train_oracle_mode\n",
    "\n",
    "        self.kwargs = kwargs\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        self.dataset_train = UnlabelledDataset(\n",
    "            self.dataset,\n",
    "            self.datapath,\n",
    "            split=\"train\",\n",
    "            transform=None,\n",
    "            n_images=self.n_images,\n",
    "            n_classes=self.n_classes,\n",
    "            n_support=self.n_support,\n",
    "            n_query=self.n_query,\n",
    "            no_aug_support=self.no_aug_support,\n",
    "            no_aug_query=self.no_aug_query,\n",
    "        )\n",
    "        if self.merge_train_val:\n",
    "            dataset_val = UnlabelledDataset(\n",
    "                self.dataset,\n",
    "                self.datapath,\n",
    "                \"val\",\n",
    "                transform=None,\n",
    "                n_support=self.n_support,\n",
    "                n_query=self.n_query,\n",
    "                no_aug_support=self.no_aug_support,\n",
    "                no_aug_query=self.no_aug_query,\n",
    "            )\n",
    "\n",
    "            self.dataset_train = ConcatDataset([self.dataset_train, dataset_val])\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        if self.train_oracle_mode == True:\n",
    "            dataloader_train = get_episode_loader(\n",
    "                self.dataset,\n",
    "                self.datapath,\n",
    "                ways=self.eval_ways,\n",
    "                shots=self.eval_support_shots,\n",
    "                test_shots=self.eval_query_shots,\n",
    "                batch_size=1,\n",
    "                split='train',\n",
    "                **self.kwargs\n",
    "            )\n",
    "        else:\n",
    "            dataloader_train = DataLoader(\n",
    "                self.dataset_train,\n",
    "                batch_size=self.batch_size,\n",
    "                shuffle=True,\n",
    "                num_workers=self.num_workers,\n",
    "                pin_memory=torch.cuda.is_available(),\n",
    "            )\n",
    "        return dataloader_train\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        dataloader_val = get_episode_loader(\n",
    "            self.dataset,\n",
    "            self.datapath,\n",
    "            ways=self.eval_ways,\n",
    "            shots=self.eval_support_shots,\n",
    "            test_shots=self.eval_query_shots,\n",
    "            batch_size=1,\n",
    "            split=\"val\",\n",
    "            **self.kwargs\n",
    "        )\n",
    "        return dataloader_val\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        dataloader_test = get_episode_loader(\n",
    "            self.dataset,\n",
    "            self.datapath,\n",
    "            ways=self.eval_ways,\n",
    "            shots=self.eval_support_shots,\n",
    "            test_shots=self.eval_query_shots,\n",
    "            batch_size=1,\n",
    "            split=\"test\",\n",
    "            shuffle=False,\n",
    "            **self.kwargs\n",
    "        )\n",
    "        return dataloader_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Omniglot data Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class OmniglotDataModule(pl.LightningDataModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        data_dir: str,\n",
    "        shots: int,\n",
    "        ways: int,\n",
    "        shuffle_ds: bool,\n",
    "        test_shots: int,\n",
    "        meta_train: bool,\n",
    "        download: bool,\n",
    "        batch_size: str,\n",
    "        shuffle: bool,\n",
    "        num_workers: int,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.data_dir = data_dir\n",
    "        self.shots = shots\n",
    "        self.ways = ways\n",
    "        self.shuffle_ds = shuffle_ds\n",
    "        self.test_shots = test_shots\n",
    "        self.meta_train = meta_train\n",
    "        self.download = download\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.num_workers = num_workers\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        self.task_dataset = omniglot(\n",
    "            self.data_dir,\n",
    "            shots=self.shots,\n",
    "            ways=self.ways,\n",
    "            shuffle=self.shuffle_ds,\n",
    "            test_shots=self.test_shots,\n",
    "            meta_train=self.meta_train,\n",
    "            download=self.download,\n",
    "        )\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return BatchMetaDataLoader(\n",
    "            self.task_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=self.shuffle,\n",
    "            num_workers=self.num_workers,\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        self.val_tasks = omniglot(\n",
    "            self.data_dir,\n",
    "            shots=self.shots,\n",
    "            ways=self.ways,\n",
    "            shuffle=self.shuffle_ds,\n",
    "            test_shots=self.test_shots,\n",
    "            meta_val=True,\n",
    "            download=self.download,\n",
    "        )\n",
    "        return BatchMetaDataLoader(\n",
    "            self.val_tasks, batch_size=self.batch_size, num_workers=self.num_workers\n",
    "        )\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        self.test_tasks = omniglot(\n",
    "            self.data_dir,\n",
    "            shots=self.shots,\n",
    "            ways=self.ways,\n",
    "            shuffle=self.shuffle_ds,\n",
    "            test_shots=self.test_shots,\n",
    "            meta_test=True,\n",
    "            download=self.download,\n",
    "        )\n",
    "        return BatchMetaDataLoader(\n",
    "            self.test_tasks, batch_size=self.batch_size, num_workers=self.num_workers\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Miniimagenet data module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class MiniImagenetDataModule(pl.LightningDataModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        data_dir: str,\n",
    "        shots: int,\n",
    "        ways: int,\n",
    "        shuffle_ds: bool,\n",
    "        test_shots: int,\n",
    "        meta_train: bool,\n",
    "        download: bool,\n",
    "        batch_size: str,\n",
    "        shuffle: bool,\n",
    "        num_workers: int,\n",
    "    ):\n",
    "        self.data_dir = data_dir\n",
    "        self.shots = shots\n",
    "        self.ways = ways\n",
    "        self.shuffle_ds = shuffle_ds\n",
    "        self.test_shots = test_shots\n",
    "        self.meta_train = meta_train\n",
    "        self.download = download\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.num_workers = num_workers\n",
    "\n",
    "    def setup(self):\n",
    "        self.train_taskset = miniimagenet(\n",
    "            self.data_dir,\n",
    "            shots=self.shots,\n",
    "            ways=self.ways,\n",
    "            shuffle=self.shuffle_ds,\n",
    "            test_shots=self.test_shots,\n",
    "            meta_train=True,\n",
    "            download=self.download,\n",
    "        )\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return BatchMetaDataLoader(\n",
    "            self.train_taskset,\n",
    "            shuffle=self.shuffle,\n",
    "            batch_size=self.batch_size,\n",
    "            num_workers=self.num_workers,\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        self.val_taskset = miniimagenet(\n",
    "            self.data_dir,\n",
    "            shots=self.shots,\n",
    "            ways=self.ways,\n",
    "            shuffle=self.shuffle_ds,\n",
    "            test_shots=self.test_shots,\n",
    "            meta_val=True,\n",
    "            download=self.download,\n",
    "        )\n",
    "        return BatchMetaDataLoader(\n",
    "            self.val_taskset,\n",
    "            shuffle=self.shuffle,\n",
    "            batch_size=self.batch_size,\n",
    "            num_workers=self.num_workers,\n",
    "        )\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        self.test_taskset = miniimagenet(\n",
    "            self.data_dir,\n",
    "            shots=self.shots,\n",
    "            ways=self.ways,\n",
    "            shuffle=False,\n",
    "            test_shots=self.test_shots,\n",
    "            meta_test=True,\n",
    "            download=self.download,\n",
    "        )\n",
    "        return BatchMetaDataLoader(\n",
    "            self.test_taskset,\n",
    "            shuffle=False,\n",
    "            batch_size=self.batch_size,\n",
    "            num_workers=self.num_workers,\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 01_nn_utils.ipynb.\n",
      "Converted 01b_data_loaders_pl.ipynb.\n",
      "Converted 01c_grad_utils.ipynb.\n",
      "Converted 01d_proto_utils.ipynb.\n",
      "Converted 02_maml_pl.ipynb.\n",
      "Converted 02b_iMAML.ipynb.\n",
      "Converted 03_protonet_pl.ipynb.\n",
      "Converted 03b_ProtoCLR.ipynb.\n",
      "Converted 04_cactus.ipynb.\n",
      "Converted jax-maml.ipynb.\n",
      "Converted lightning-vae.ipynb.\n",
      "Converted unsupervised_loaders.ipynb.\n",
      "Converted index.ipynb.\n",
      "Converted scratch.ipynb.\n"
     ]
    }
   ],
   "source": [
    "from nbdev.export import notebook2script; notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9c07cba5fc4ead51138727dff7e3432f9ddfc5280df3e75c751c30010a4f78a5"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('ai': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
