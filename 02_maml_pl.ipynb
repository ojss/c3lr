{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22bacb13-3bbd-4e17-bbe3-ca0520aaad83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp maml\n",
    "#export\n",
    "import logging\n",
    "import warnings \n",
    "\n",
    "import higher\n",
    "import kornia as K\n",
    "import wandb\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchmetrics\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from copy import deepcopy\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint\n",
    "from pytorch_lightning.loggers import WandbLogger, TensorBoardLogger\n",
    "from pytorch_lightning.metrics.functional import accuracy\n",
    "from torchmeta.datasets.helpers import omniglot\n",
    "from torchmeta.utils.data import BatchMetaDataLoader\n",
    "from unsupervised_meta_learning.pl_dataloaders import OmniglotDataModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc7bfc6-5fb5-4825-90fb-9429697c5409",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be03bb5-a108-4e93-a3be-c0001c8c6337",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4b3d49-5aff-46c8-aed3-e37412b35106",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ConvolutionalNeuralNetwork(nn.Module):\n",
    "    def __init__(self, in_channels, out_features, hidden_size=64):\n",
    "        super(ConvolutionalNeuralNetwork, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_features = out_features\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.features = nn.Sequential(\n",
    "            self.conv3x3(in_channels, hidden_size),\n",
    "            self.conv3x3(hidden_size, hidden_size),\n",
    "            self.conv3x3(hidden_size, hidden_size),\n",
    "            self.conv3x3(hidden_size, hidden_size),\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Linear(hidden_size, out_features)\n",
    "\n",
    "    def forward(self, inputs, params=None):\n",
    "        features = self.features(inputs)\n",
    "        features = features.view((features.size(0), -1))\n",
    "        logits = self.classifier(features)\n",
    "        return logits\n",
    "\n",
    "    def conv3x3(self, in_channels, out_channels, **kwargs):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, **kwargs),\n",
    "            nn.BatchNorm2d(out_channels, momentum=1.0, track_running_stats=False),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30c62b6-25f8-4f8d-bfa6-8b1049d3287a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_accuracy(logits, targets):\n",
    "    \"\"\"Compute the accuracy (after adaptation) of MAML on the test/query points\n",
    "    Parameters\n",
    "    ----------\n",
    "    logits : `torch.FloatTensor` instance\n",
    "        Outputs/logits of the model on the query points. This tensor has shape\n",
    "        `(num_examples, num_classes)`.\n",
    "    targets : `torch.LongTensor` instance\n",
    "        A tensor containing the targets of the query points. This tensor has \n",
    "        shape `(num_examples,)`.\n",
    "    Returns\n",
    "    -------\n",
    "    accuracy : `torch.FloatTensor` instance\n",
    "        Mean accuracy on the query points\n",
    "    \"\"\"\n",
    "    _, predictions = torch.max(logits, dim=-1)\n",
    "    return torch.mean(predictions.eq(targets).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf69734-98e0-4768-9f8f-8100bfd31382",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class MAML(pl.LightningModule):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.accuracy = get_accuracy\n",
    "        self.automatic_optimization = False\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    def training_step(self, batch, batch_idx, optimizer_idx):\n",
    "        meta_optimizer, inner_optimizer = self.optimizers()\n",
    "        meta_optimizer = meta_optimizer.optimizer\n",
    "        inner_optimizer = inner_optimizer.optimizer\n",
    "        \n",
    "        train_inputs, train_targets = batch['train']\n",
    "        test_inputs, test_targets = batch['test']\n",
    "        \n",
    "        batch_size = train_inputs.shape[0]\n",
    "        outer_loss = torch.tensor(0., device=self.device)\n",
    "        acc = torch.tensor(0., device=self.device)\n",
    "        self.model.zero_grad()\n",
    "        \n",
    "        for task_idx, (train_input, train_target, test_input, test_target) in enumerate(\n",
    "            zip(train_inputs, train_targets, test_inputs, test_targets)\n",
    "        ):\n",
    "#             inner_optimizer.zero_grad()\n",
    "            with higher.innerloop_ctx(self.model, inner_optimizer, copy_initial_weights=False) as (fmodel, diffopt):\n",
    "                train_logit = fmodel(train_input)\n",
    "                inner_loss = F.cross_entropy(train_logit, train_target)\n",
    "                \n",
    "                diffopt.step(inner_loss)\n",
    "                \n",
    "                test_logit = fmodel(test_input)\n",
    "                outer_loss += F.cross_entropy(test_logit, test_target)\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    preds = test_logit.softmax(dim=-1)\n",
    "                    acc += self.accuracy(test_logit, test_target)\n",
    "                \n",
    "\n",
    "#                     self.print(self.accuracy(test_logit, test_target))\n",
    "                \n",
    "        outer_loss.div_(batch_size)\n",
    "        acc.div_(batch_size)\n",
    "        self.log_dict({\n",
    "                    'outer_loss': outer_loss,\n",
    "                    'accuracy': acc\n",
    "                }, prog_bar=True)\n",
    "        \n",
    "        meta_optimizer.zero_grad()\n",
    "#         outer_loss.backward()\n",
    "\n",
    "        self.manual_backward(outer_loss, meta_optimizer)\n",
    "        meta_optimizer.step()\n",
    "        \n",
    "        return outer_loss\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        meta_optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "        inner_optimizer = torch.optim.SGD(self.parameters(), lr=1e-1)\n",
    "        \n",
    "        return [meta_optimizer, inner_optimizer]\n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc7a973-d7cf-4a19-892a-e56d211c103f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class UMTRA(pl.LightningModule):\n",
    "    def __init__(self, model, augmentation):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.accuracy = get_accuracy\n",
    "        self.augmentation = augmentation\n",
    "        self.automatic_optimization = False\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    def training_step(self, batch, batch_idx, optimizer_idx):\n",
    "        meta_optimizer, inner_optimizer = self.optimizers()\n",
    "        meta_optimizer = meta_optimizer.optimizer\n",
    "        inner_optimizer = inner_optimizer.optimizer\n",
    "        \n",
    "        train_inputs, train_targets = batch['train']\n",
    "        test_inputs, test_targets = batch['test']\n",
    "        \n",
    "        batch_size = train_inputs.shape[0]\n",
    "        outer_loss = torch.tensor(0., device=self.device)\n",
    "        acc = torch.tensor(0., device=self.device)\n",
    "        self.model.zero_grad()\n",
    "        \n",
    "        for task_idx, (train_input, train_target, test_input, test_target) in enumerate(\n",
    "            zip(train_inputs, train_targets, test_inputs, test_targets)\n",
    "        ):\n",
    "#             inner_optimizer.zero_grad()\n",
    "            val_input = self.augmentation(train_input).to(self.device)\n",
    "            val_target = deepcopy(train_target).to(self.device)\n",
    "            with higher.innerloop_ctx(self.model, inner_optimizer, copy_initial_weights=False) as (fmodel, diffopt):\n",
    "                train_logit = fmodel(train_input)\n",
    "                inner_loss = F.cross_entropy(train_logit, train_target)\n",
    "                \n",
    "                diffopt.step(inner_loss)\n",
    "                \n",
    "                val_logits = fmodel(val_input)\n",
    "                outer_loss += F.cross_entropy(val_logits, val_target)\n",
    "#                 test_logit = fmodel(test_input)\n",
    "#                 outer_loss += F.cross_entropy(test_logit, test_target)\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    test_logits = fmodel(test_input)\n",
    "                    acc += self.accuracy(test_logits, test_target)\n",
    "                \n",
    "\n",
    "#                     self.print(self.accuracy(test_logit, test_target))\n",
    "                \n",
    "        outer_loss.div_(batch_size)\n",
    "        acc.div_(batch_size)\n",
    "        self.log_dict({\n",
    "                    'outer_loss': outer_loss,\n",
    "                    'accuracy': acc\n",
    "                }, prog_bar=True)\n",
    "        \n",
    "        meta_optimizer.zero_grad()\n",
    "#         outer_loss.backward()\n",
    "\n",
    "        self.manual_backward(outer_loss, meta_optimizer)\n",
    "        meta_optimizer.step()\n",
    "        \n",
    "        return outer_loss\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        meta_optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "        inner_optimizer = torch.optim.SGD(self.parameters(), lr=1e-1)\n",
    "        \n",
    "        return [meta_optimizer, inner_optimizer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e7e713-faf8-4145-b8fb-e995a7cf487c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = OmniglotDataModule(\n",
    "        \"data\",\n",
    "        shots=1,\n",
    "        ways=5,\n",
    "        shuffle_ds=True,\n",
    "        test_shots=15,\n",
    "        meta_train=True,\n",
    "        download=True,\n",
    "        batch_size=16,\n",
    "        shuffle=True,\n",
    "        num_workers=8,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930a6e63-22f0-44e0-9486-cb60e7946368",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm.setup()\n",
    "batch =dm.train_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02fd24ac-9e51-4d4d-ae5c-8f4458f0b593",
   "metadata": {},
   "outputs": [],
   "source": [
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    batch = next(iter(batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77af0ba2-ee5c-4a5b-895f-e8a6ab5c9e1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4, 2, 0, 3, 1])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['train'][1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91626c3-610a-4764-a3ea-d12b671c186a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def c_imshow(img):\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf1e3e8-84f2-425a-9d8e-cca28074dc3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "c_imshow(torchvision.utils.make_grid(batch['train'][0][2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2067af73-1a84-4498-bb44-da7a88e93068",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MAML(model=ConvolutionalNeuralNetwork(1, 5, hidden_size=64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919419b4-02a7-4119-a180-89161a124fab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n"
     ]
    }
   ],
   "source": [
    "logger = WandbLogger(\n",
    "    project='maml',\n",
    "    config={\n",
    "        'batch_size': 16,\n",
    "        'steps': 100,\n",
    "        'dataset': \"omniglot\"\n",
    "    }\n",
    ")\n",
    "trainer = Trainer(\n",
    "        profiler='simple',\n",
    "        max_epochs=100,\n",
    "        max_steps=100,\n",
    "        fast_dev_run=False,\n",
    "        num_sanity_val_steps=2, gpus=1, logger=logger\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d445dfb-84ea-44c3-bd11-75516b58df96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mp0int\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.31<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">lemon-durian-9</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/p0int/maml\" target=\"_blank\">https://wandb.ai/p0int/maml</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/p0int/maml/runs/35k4n9mz\" target=\"_blank\">https://wandb.ai/p0int/maml/runs/35k4n9mz</a><br/>\n",
       "                Run data is saved locally in <code>/home/ojass/Projects/meta-learning/wandb/run-20210605_164710-35k4n9mz</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name  | Type                       | Params\n",
      "-----------------------------------------------------\n",
      "0 | model | ConvolutionalNeuralNetwork | 112 K \n",
      "-----------------------------------------------------\n",
      "112 K     Trainable params\n",
      "0         Non-trainable params\n",
      "112 K     Total params\n",
      "0.449     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7111adaab03d49ea9f30d9e5125ccaf1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FIT Profiler Report\n",
      "\n",
      "Action                             \t|  Mean duration (s)\t|Num calls      \t|  Total time (s) \t|  Percentage %   \t|\n",
      "--------------------------------------------------------------------------------------------------------------------------------------\n",
      "Total                              \t|  -              \t|_              \t|  37.018         \t|  100 %          \t|\n",
      "--------------------------------------------------------------------------------------------------------------------------------------\n",
      "run_training_epoch                 \t|  25.132         \t|1              \t|  25.132         \t|  67.89          \t|\n",
      "run_training_batch                 \t|  0.23588        \t|100            \t|  23.588         \t|  63.721         \t|\n",
      "model_forward                      \t|  0.23573        \t|100            \t|  23.573         \t|  63.68          \t|\n",
      "training_step                      \t|  0.23543        \t|100            \t|  23.543         \t|  63.599         \t|\n",
      "get_train_batch                    \t|  0.010373       \t|100            \t|  1.0373         \t|  2.802          \t|\n",
      "on_train_batch_end                 \t|  0.001595       \t|100            \t|  0.1595         \t|  0.43087        \t|\n",
      "on_train_start                     \t|  0.029097       \t|1              \t|  0.029097       \t|  0.078601       \t|\n",
      "cache_result                       \t|  1.9307e-05     \t|408            \t|  0.0078772      \t|  0.021279       \t|\n",
      "on_train_epoch_start               \t|  0.002225       \t|1              \t|  0.002225       \t|  0.0060105      \t|\n",
      "on_batch_start                     \t|  1.9889e-05     \t|100            \t|  0.0019889      \t|  0.0053727      \t|\n",
      "on_train_batch_start               \t|  1.1239e-05     \t|100            \t|  0.0011239      \t|  0.0030361      \t|\n",
      "on_batch_end                       \t|  1.0781e-05     \t|100            \t|  0.0010781      \t|  0.0029123      \t|\n",
      "training_step_end                  \t|  1.0636e-05     \t|100            \t|  0.0010636      \t|  0.0028733      \t|\n",
      "on_train_end                       \t|  0.00073687     \t|1              \t|  0.00073687     \t|  0.0019906      \t|\n",
      "on_train_epoch_end                 \t|  9.4164e-05     \t|1              \t|  9.4164e-05     \t|  0.00025437     \t|\n",
      "on_epoch_start                     \t|  1.8442e-05     \t|1              \t|  1.8442e-05     \t|  4.9819e-05     \t|\n",
      "on_before_accelerator_backend_setup\t|  1.5335e-05     \t|1              \t|  1.5335e-05     \t|  4.1426e-05     \t|\n",
      "on_train_dataloader                \t|  1.4623e-05     \t|1              \t|  1.4623e-05     \t|  3.9502e-05     \t|\n",
      "on_fit_start                       \t|  1.4076e-05     \t|1              \t|  1.4076e-05     \t|  3.8025e-05     \t|\n",
      "on_epoch_end                       \t|  8.837e-06      \t|1              \t|  8.837e-06      \t|  2.3872e-05     \t|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    trainer.fit(model, datamodule=dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6e1925-5569-47d7-9399-fb48f50ddab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.finalize(\"success\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a42450-d257-4a0c-8052-e973f6ab9bf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 72390<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/ojass/Projects/meta-learning/wandb/run-20210605_164710-35k4n9mz/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/ojass/Projects/meta-learning/wandb/run-20210605_164710-35k4n9mz/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>outer_loss</td><td>0.29954</td></tr><tr><td>accuracy</td><td>0.90917</td></tr><tr><td>epoch</td><td>0</td></tr><tr><td>trainer/global_step</td><td>99</td></tr><tr><td>_runtime</td><td>29</td></tr><tr><td>_timestamp</td><td>1622904459</td></tr><tr><td>_step</td><td>1</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>outer_loss</td><td>█▁</td></tr><tr><td>accuracy</td><td>▁█</td></tr><tr><td>epoch</td><td>▁▁</td></tr><tr><td>trainer/global_step</td><td>▁█</td></tr><tr><td>_runtime</td><td>▁█</td></tr><tr><td>_timestamp</td><td>▁█</td></tr><tr><td>_step</td><td>▁█</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">lemon-durian-9</strong>: <a href=\"https://wandb.ai/p0int/maml/runs/35k4n9mz\" target=\"_blank\">https://wandb.ai/p0int/maml/runs/35k4n9mz</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61159219-fa62-4ef1-845a-1a22521394b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "aug = nn.Sequential(\n",
    "    K.augmentation.RandomAffine(degrees=0, translate=(0.4, 0.4), padding_mode='border'),\n",
    "    K.augmentation.RandomGaussianNoise(mean=0., std=.1, p=.3)\n",
    ")\n",
    "model = UMTRA(model=ConvolutionalNeuralNetwork(1, 5, hidden_size=64), augmentation=aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d75b5e-5fea-4699-88a8-ef6af51b8583",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n"
     ]
    }
   ],
   "source": [
    "logger = WandbLogger(\n",
    "    project='umtra',\n",
    "    config={\n",
    "        'batch_size': 16,\n",
    "        'steps': 100,\n",
    "        'dataset': \"omniglot\"\n",
    "    }\n",
    ")\n",
    "trainer = Trainer(\n",
    "        profiler='simple',\n",
    "        max_epochs=100,\n",
    "        max_steps=100,\n",
    "        fast_dev_run=False,\n",
    "        num_sanity_val_steps=2, gpus=1, logger=logger\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c68b428-ce6c-4c94-90cf-8beeb08b88ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.31<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">ethereal-water-2</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/p0int/umtra\" target=\"_blank\">https://wandb.ai/p0int/umtra</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/p0int/umtra/runs/3ab6fih1\" target=\"_blank\">https://wandb.ai/p0int/umtra/runs/3ab6fih1</a><br/>\n",
       "                Run data is saved locally in <code>/home/ojass/Projects/meta-learning/wandb/run-20210605_171038-3ab6fih1</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name         | Type                       | Params\n",
      "------------------------------------------------------------\n",
      "0 | model        | ConvolutionalNeuralNetwork | 112 K \n",
      "1 | augmentation | Sequential                 | 0     \n",
      "------------------------------------------------------------\n",
      "112 K     Trainable params\n",
      "0         Non-trainable params\n",
      "112 K     Total params\n",
      "0.449     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83c5d82221114478b5646330977ce5dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FIT Profiler Report\n",
      "\n",
      "Action                             \t|  Mean duration (s)\t|Num calls      \t|  Total time (s) \t|  Percentage %   \t|\n",
      "--------------------------------------------------------------------------------------------------------------------------------------\n",
      "Total                              \t|  -              \t|_              \t|  36.018         \t|  100 %          \t|\n",
      "--------------------------------------------------------------------------------------------------------------------------------------\n",
      "run_training_epoch                 \t|  31.24          \t|1              \t|  31.24          \t|  86.733         \t|\n",
      "run_training_batch                 \t|  0.29617        \t|100            \t|  29.617         \t|  82.227         \t|\n",
      "model_forward                      \t|  0.29602        \t|100            \t|  29.602         \t|  82.185         \t|\n",
      "training_step                      \t|  0.29571        \t|100            \t|  29.571         \t|  82.099         \t|\n",
      "get_train_batch                    \t|  0.011208       \t|100            \t|  1.1208         \t|  3.1117         \t|\n",
      "on_train_batch_end                 \t|  0.0017598      \t|100            \t|  0.17598        \t|  0.48859        \t|\n",
      "on_train_start                     \t|  0.016859       \t|1              \t|  0.016859       \t|  0.046808       \t|\n",
      "cache_result                       \t|  2.0605e-05     \t|408            \t|  0.008407       \t|  0.023341       \t|\n",
      "on_batch_start                     \t|  2.0373e-05     \t|100            \t|  0.0020373      \t|  0.0056562      \t|\n",
      "on_train_epoch_start               \t|  0.0014782      \t|1              \t|  0.0014782      \t|  0.004104       \t|\n",
      "on_train_batch_start               \t|  1.1124e-05     \t|100            \t|  0.0011124      \t|  0.0030883      \t|\n",
      "on_batch_end                       \t|  1.0705e-05     \t|100            \t|  0.0010705      \t|  0.0029722      \t|\n",
      "training_step_end                  \t|  1.0611e-05     \t|100            \t|  0.0010611      \t|  0.002946       \t|\n",
      "on_train_end                       \t|  0.00081267     \t|1              \t|  0.00081267     \t|  0.0022563      \t|\n",
      "on_train_epoch_end                 \t|  0.00011435     \t|1              \t|  0.00011435     \t|  0.00031748     \t|\n",
      "on_fit_start                       \t|  2.9168e-05     \t|1              \t|  2.9168e-05     \t|  8.0981e-05     \t|\n",
      "on_before_accelerator_backend_setup\t|  2.7907e-05     \t|1              \t|  2.7907e-05     \t|  7.748e-05      \t|\n",
      "on_epoch_end                       \t|  1.2155e-05     \t|1              \t|  1.2155e-05     \t|  3.3747e-05     \t|\n",
      "on_train_dataloader                \t|  1.1593e-05     \t|1              \t|  1.1593e-05     \t|  3.2186e-05     \t|\n",
      "on_epoch_start                     \t|  1.0118e-05     \t|1              \t|  1.0118e-05     \t|  2.8091e-05     \t|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    trainer.fit(model, datamodule=dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2192dceb-338b-4bfe-a05b-b37a6378d525",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 76864<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/ojass/Projects/meta-learning/wandb/run-20210605_171038-3ab6fih1/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/ojass/Projects/meta-learning/wandb/run-20210605_171038-3ab6fih1/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>outer_loss</td><td>0.26876</td></tr><tr><td>accuracy</td><td>0.83417</td></tr><tr><td>epoch</td><td>0</td></tr><tr><td>trainer/global_step</td><td>99</td></tr><tr><td>_runtime</td><td>35</td></tr><tr><td>_timestamp</td><td>1622905873</td></tr><tr><td>_step</td><td>1</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>outer_loss</td><td>█▁</td></tr><tr><td>accuracy</td><td>▁█</td></tr><tr><td>epoch</td><td>▁▁</td></tr><tr><td>trainer/global_step</td><td>▁█</td></tr><tr><td>_runtime</td><td>▁█</td></tr><tr><td>_timestamp</td><td>▁█</td></tr><tr><td>_step</td><td>▁█</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">ethereal-water-2</strong>: <a href=\"https://wandb.ai/p0int/umtra/runs/3ab6fih1\" target=\"_blank\">https://wandb.ai/p0int/umtra/runs/3ab6fih1</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae0ad69-fbc6-46dd-b849-11158faa876a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 01_nn_utils.ipynb.\n",
      "Converted 01b_data_loaders_pl.ipynb.\n",
      "Converted 02_maml.ipynb.\n",
      "Converted 02b_maml_pl.ipynb.\n",
      "Converted 03_protonet_pl.ipynb.\n",
      "Converted 04_cactus.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "from nbdev.export import notebook2script; notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a9caad-734d-41fb-8aa5-189f0a3f67bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
